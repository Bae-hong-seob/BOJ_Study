{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visual computing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxsG8uOm/SR3cw08/XMlW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bae-hong-seob/BOJ_Study/blob/main/visual_computing/visual%20computing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBV4SrJ16Tg_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m0kO1YxeBGv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3/2 첫 수업 note. \n",
        "\n",
        "OpenCV : 영상처리  \n",
        "TensorFlow : AI 할때 사용할 것  \n",
        "\n",
        "파이썬과 관련된 코딩능력이 필요할 것  \n",
        "\n",
        "이번 강의에서 컴퓨터 비전, 이미지 프로세싱 두 기술에 AI가 어떻게 적용될 수 있는가를 배우게 된다.  \n",
        "\n",
        ">1. 중간고사만 있고, 기말고사는 없음  \n",
        ">2. 중간 30, 과제 30, 기말프로젝트 30  \n",
        ">3. 코드 참조 쌉가능, 참조시 표기만 잘하기  \n",
        ">4. 기말프로젝트는 3-4인  \n",
        ">5. 3번 지각 -> 1번 결석  \n",
        "\n",
        "what does lab do?  \n",
        "메타휴먼에 관심이 많고, 언리얼 엔진을 주로 쓴다.  \n",
        "low-level 코딩도 한다. "
      ],
      "metadata": {
        "id": "4-WLKHBY6Zo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3/7 두번째 수업 note.\n",
        "\n",
        "사람이 빛을 받아들이는 색 -> 가시광선  \n",
        "이로써 사물을 인식하게 되는데 이떄 필터가 씌이게 되면 관련된 색이 잘 안보인다  \n",
        "> ex) 파란색 필터 속에서 색을 받아들일때 rgb 중 blue 계열은 값을 0과 가깝게 확 줄여버린다  \n",
        "> 이를 chromatic adaptation 이라고 한다.  \n",
        "\n",
        "빛의 3원색 -> 섞으면 흰색이 나온다    \n",
        "잉크의 관점에서는 세 색을 섞으면 검은색이 됨  \n",
        "> primary colors(Red, Green, Blue)를 섞으면 모든 색을 표현할 수 있다.  \n",
        "> 따라서 target color를 rgb의 조합으로 표현할 수 있는데 이것을 colorimetry라고 한다.\n",
        "\n",
        "모든 색은 파장으로 정의될 수 있는데 이걸 rgb 조합으로 represent 하고 싶다.  \n",
        "따라서 test color를 white screen에 쏜 다음, r,g,b의 빛을 white screen에 쏜다.  \n",
        "r,g,b에는 각각 weight가 존재하고 이러한 weight를 조절하면서 test color에 맞는 r,g,b 조합을 찾게된다.  \n",
        "\n",
        "1. CIE RGB 표준방법 -> 관찰을 통해서 표준화\n",
        "\n",
        "빨간색은 파장이 더 기므로 에너지가 약하다.  \n",
        "따라서 radiant power ratios를 다르게 해서 radiant power를 맞춰주어야 한다.  \n",
        "이때 표준화 시켜보았는데 마이너스 값이 존재한다 -> Negative values  \n",
        "\n",
        "2. CIE XYZ 표준방법 -> CIE RGB에 수학적인 방식을 더하여 만든 표준화  \n",
        "세가지 properties 존재  \n",
        "\n",
        "3. CIE xyY 표준방법 -> CIE XYZ는 수학적인 관점에서 모델링해서 알아보기 힘들었음.  \n",
        "따라서 보기 쉽게 만든 표준 방법이 CIE xyY\n",
        "\n",
        "4. Standard RGB  \n",
        "CIE XYZ를 다시 RGB 관점으로 변화시키는 것  \n",
        "따라서 흐름 CIE RGB -> CIE XYZ -> standard RGB로 변화시키기.  \n",
        "> sRGB의 배경  \n",
        "> 1. 색을 표준화 시켜서 표현할 방법을 찾다가 나온 것은 CIE RGB, \n",
        "> 2. 그것을 수학적인 관점으로 표현하고 싶어서 CIE XYZ 등장  \n",
        "> 3. 그것을 industry 관점에서 다시 RGB관점으로 만들고 싶어서 sRGB 생성  \n",
        "\n",
        "감마커브??  \n",
        "> 우리는 밝은색을 조금 더 편하게 느끼기 때문에 적절한 값을 적용하여 화면에 띄워주기 위한 그래프  \n",
        "> 감마값이 작아질 수록 원래 rgb 조합이 표현한 색의 휘도값이 조정됨 (=밝아짐)  \n",
        "\n",
        "이미지 프로세싱에 맞춰서 컬러모델을 다양하게 사용해야한다.  \n",
        "이 중에 CIE RGB or sRGB 등등 은 하나의 모델일 뿐 잘 맞춰서 사용해야한다.  \n",
        "\n",
        "렌즈 setting for Exposure(노출)  \n",
        "> 센서 : light receiver that determines brightness of image. \n",
        "> 노출 : exposure affects the brightness of image by exposing the sensor from light. \n",
        "\n",
        "page 40. \n",
        "exposure by aperture and shutter speed. \n",
        "> aperture(구멍) : The larger aperture the more light  \n",
        "> shutter speed : The slower shutter speed the more light\n",
        "\n",
        "page 41. \n"
      ],
      "metadata": {
        "id": "BxnXHLMTUpPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3/14 세번째 수업내용 note\n",
        "\n",
        "질문에 대한 답변 먼저 진행  \n",
        "\n",
        "1. CIE(1931) RGB 표준 방법  \n",
        "> R, G, B 세가지 색을 섞으면 모든 색 표현 가능하다는 원리를 사용  \n",
        "> 이떄 그래프를 관측하면 마이너스 값(negative value) 를 가진다.  \n",
        "> 그런데 빛은 0은 검정색, 255는 흰색으로 표현되지 않는가. 그럼 마이너스 값은 뭘 뜻하지..?  \n",
        ">> R, G, B 기준으로 G,B만 섞어서 만들 수 있는 색이 존재. 이때 R이 무색인 경우는 없다. 흰색을 섞어도 색이 옅어지기 때문에 R을 오히려 빼는게 나을 수 도 있다. 이를 마이너스 값으로 표현한건데 어떻게 구현했나? test color 표현 용지에 오히려 R 색을 쏘아서 무마시킴  \n",
        ">> 여기서 질문. 그렇다면 G, B 값은 negative value가 왜 측정되지 않는가??\n",
        "\n",
        "\n",
        "\n",
        "Effects by Aperture and shutter speed.  \n",
        "\n",
        "센서는 빛의 세기를 인식하는 장치  \n",
        "color filter로 하나의 색만 어느 세기로 들어오는지 관측 가능.  \n",
        "근데 우린 3가지 색이 필요하다. 그럼 어떻게 하나?  \n",
        "\n",
        "첫번째 방법  \n",
        "1. simple interpolation  \n",
        "여러개의 센서(매우 작음) 을 활용하여 바둑판과 같은 구조로 센서를 배치한다  \n",
        "> R G R  \n",
        "> G B G  \n",
        "> R G R     대충 이런 구조  \n",
        "> 이때 가운데 B에 대해서 R, G를 계산해서 하나의 색이라고 인식한다(평균값 사용) -> 센서가 매우 작기때문에 색 표현에 용이할 수 있음  \n",
        "\n",
        "\n",
        "\n",
        "카메라 이미지 프로세싱 과정  \n",
        "\n",
        "1. ISO setting  \n",
        "2. RGB Demosaicing\n",
        "3. Noise Reduction\n",
        "> \n",
        "4. White balance\n",
        "> 센서가 받아들이는 색을 마치 백색 조명 하에서 찍힌 영상처럼 이미지 프로세싱 해준다. matrix는 회사마다 값이 존재하고, 센서가 받아들인 색의 조합을 CIE XYZ 표준방법에 맞게 매칭시키게끔 바꾸는 matrix function이 기술력이다.  \n",
        "5. color manipulation\n",
        "> 포토샵 같은 단계. \n",
        "\n",
        "\n",
        "raw-RGB values -> white balance 맞추고 -> mapped to CIE XYZ 이런 process 과정이 일반적  \n",
        "\n",
        "\n",
        "Global tone-mapping 모다 local-tone-mapping이 더 고급 기법. \n",
        "Local Tone Mapping(LTM)  \n",
        "\n",
        "Summary 내용 -> 강의를 포괄하는 큰틀.  \n",
        "CIE RGB 표준 방법 -> 수학적으로 negative value 존재, 빛의 더하는 연산만 존재하고 빼는 연산이 존재하지 않음  \n",
        "따라서 수학적으로 조금 더 발전시킨 CIE XYZ 표준 방법 고안  \n",
        "하지만 이것도 그래프 모양이 R이 좀 이상함.  \n",
        "이후 나온 표준 방법이 sRGB 표준방법.  \n",
        "\n",
        "이미지 센서가 받아들인다면 raw RGB로 표현되어 있음.  \n",
        "\n",
        "이것을 white balance를 거쳐 CIE XYZ와 mapping한 후 sRGB 표준방법으로 표현한다. "
      ],
      "metadata": {
        "id": "O3TXgoNLYUmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3/16 네번째 수업 Note\n",
        "\n",
        "이미지 프로세싱 시작 & 실습도 같이 진행  \n",
        "openCV라는 라이브러리 활용.  \n",
        "\n",
        "1. Histogram and Thresholding  \n",
        "> 히스토그램(Histogram)  \n",
        ">> \n",
        "\n",
        "openCV 는 b g r 로 색을 받아들인다.  \n",
        "다른건 r g b 순서로 색을 받아들인다. -> 유의  \n",
        "\n",
        "사용 라이브러리 : openCV, numpy, matplotlib 의 pyplot  \n",
        "\n",
        "openCV 라이브러리 내 사용 function\n",
        "> 1. cv.imread(\"파일명\")  \n",
        "> 2. cv.cvtColor(파일명, cv.COLOR_BGR2BGR)  \n",
        ">> openCV는 bgr 색으로 받아들이기 떄문에 convert 과정이 필요  \n",
        "\n",
        "> 3. cv.calcHist([img_array], [color channel], [mask] = None, [histsize], [range])  \n",
        "hist_r = cv.calcHist([img_bgr], [0], None, [256], [0,255]) -> parameter 학습  \n",
        "\n",
        ">> color_channel 질문. openCV 는 b,g,r 순으로 색을 받아들인다고 했는데 왜 r channel 을 받아들일때 0을 사용하는가?? \n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt 내 사용 function  \n",
        "> 1. plt.subplot(1,2,2). \n",
        "> 2. plt.imshow(\"파일명\")  \n",
        "> 3. plt.title(\"창 이름\")  \n",
        "\n",
        "\n",
        "Qustion : 단일채널(흑백사진) 출력 and 히스토그램으로 표현해보기. \n",
        "\n",
        "\n",
        "Thresholding : 정의 찾아보기  \n",
        "> ex) Threshold 값 보다 큰 값은 검은색, 작은 값은 흰색으로 처리 -> 임계값(기준값)  \n",
        "\n",
        "Global Thresholding : 하나의 global threshold 를 가지고 이미지 프로세싱  \n",
        "Adaptive mean Thresholding(= local threshold) : 여러개의 threshold 값을 가지고 이미지 프로세싱 -> 영역에 따라서 다른 threshold 값을 가지는 것을 adaptive mean thresholding이라고 한다.  \n",
        "\n",
        "> 4. ret, thresh1 = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
        ">> retval, threshold 를 ouput으로 받는다.  \n",
        ">> img(input) 값에 대해 127보다 큰 값, 255보다 작은값에 대해 threshold값을 선정.  \n",
        "\n",
        "Threshold value를 어떻게 잘 설정해야하나 ?  \n",
        "> 수학적으로 영상을 분석해서 분류를 할 수 있는 기준점(임계값 = threshold)을 찾을 수 있지 않을까?  \n",
        "> 대표적인 방법(Otsu method) : 히스토그램 분포를 분석해서 threshold value를 찾는 것  \n",
        ">> 히스토그램에서 값이 낮게 나오는 지점을 잡게 된다면 그것을 기준점으로 분포가 높은 지점을 나누고 기준점이 될 수 있지 않을까?  \n",
        ">> 따라서 Variance 분석. Variance 란 값의 분산 정도.  \n",
        ">> Variance가 낮다? == 분산이 많이되어 있다, 흩어져있다.  \n",
        ">> 그럼 Variance가 높은점을 Threshold value로 설정하면 된다.  \n",
        "\n",
        "주어진 영상을 threshold =127이 아닌 Otsu Thresholding으로 해보기"
      ],
      "metadata": {
        "id": "FpJwE5UjBIh7"
      }
    }
  ]
}